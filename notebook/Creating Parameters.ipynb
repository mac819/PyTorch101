{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8193f77d",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Tensors\" data-toc-modified-id=\"Tensors-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Tensors</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tensor:-Shape\" data-toc-modified-id=\"Tensor:-Shape-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Tensor: Shape</a></span></li><li><span><a href=\"#Tensor:-Reshape\" data-toc-modified-id=\"Tensor:-Reshape-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Tensor: Reshape</a></span></li></ul></li><li><span><a href=\"#Loading-Data,-Devices,-and-CUDA\" data-toc-modified-id=\"Loading-Data,-Devices,-and-CUDA-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Loading Data, Devices, and CUDA</a></span><ul class=\"toc-item\"><li><span><a href=\"#Numpy-to-PyTorch-tensor\" data-toc-modified-id=\"Numpy-to-PyTorch-tensor-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Numpy to PyTorch tensor</a></span></li><li><span><a href=\"#PyTorch-Tensor-to-Numpy\" data-toc-modified-id=\"PyTorch-Tensor-to-Numpy-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>PyTorch Tensor to Numpy</a></span></li><li><span><a href=\"#GPU-Tensors\" data-toc-modified-id=\"GPU-Tensors-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>GPU Tensors</a></span></li></ul></li><li><span><a href=\"#Creating-Parameters\" data-toc-modified-id=\"Creating-Parameters-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Creating Parameters</a></span><ul class=\"toc-item\"><li><span><a href=\"#First-Attempt\" data-toc-modified-id=\"First-Attempt-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>First Attempt</a></span></li><li><span><a href=\"#Second-Attempt\" data-toc-modified-id=\"Second-Attempt-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Second Attempt</a></span></li><li><span><a href=\"#Third-Attempt\" data-toc-modified-id=\"Third-Attempt-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Third Attempt</a></span></li><li><span><a href=\"#Fourth-Attempt\" data-toc-modified-id=\"Fourth-Attempt-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Fourth Attempt</a></span></li></ul></li><li><span><a href=\"#Autograd\" data-toc-modified-id=\"Autograd-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Autograd</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83a8269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeace75e",
   "metadata": {},
   "source": [
    "`Torch has similar functions to numpy for creating Scalar/Vector/Matrix like ones, zeros and random numbers`\n",
    "`All numbers are created as tensor objects`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d631ce7",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7719a986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1416)\n",
      "tensor([1, 2, 3])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[[-0.1906, -1.1328,  0.4272, -0.7133],\n",
      "         [ 1.4926,  2.4325, -0.0694, -0.6471],\n",
      "         [ 0.4810,  0.6902, -1.3658,  0.8439]],\n",
      "\n",
      "        [[-0.1628,  1.9884, -0.4888,  0.1109],\n",
      "         [-0.2573, -0.1808,  0.0487,  0.8678],\n",
      "         [ 1.0138,  0.6575, -0.2455, -2.1898]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# creating a scalar, and three tensors (vector, matrix, tensor)\n",
    "scalar = torch.tensor(3.14159)\n",
    "vector = torch.tensor([1, 2, 3])\n",
    "matrix = torch.ones((2, 3), dtype=torch.float)\n",
    "tensor = torch.randn((2, 3, 4), dtype=torch.float)\n",
    "\n",
    "print(scalar)\n",
    "print(vector)\n",
    "print(matrix)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74941167",
   "metadata": {},
   "source": [
    "`We can get dimensions of tensor using either size() or shape method`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a6ba1f",
   "metadata": {},
   "source": [
    "### Tensor: Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7486df0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4]) torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(tensor.shape, tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa54b5b0",
   "metadata": {},
   "source": [
    "`All the tensors have shapes, but scalars have empty shapes since they are dimansionless (or zero dimansions)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfa05d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "scalar = torch.tensor(3.14159)\n",
    "print(scalar.shape, scalar.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876935bc",
   "metadata": {},
   "source": [
    "### Tensor: Reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819e9bc8",
   "metadata": {},
   "source": [
    "`We can reshape tensors either using view() method or reshape() method`\n",
    "- `The view() method only returns a tensor with the desired shape that shares the underlying data with the original tensor; it does not create a new, independent tensor`\n",
    "- `The reshape() method may or may not create a copy! for this behavior view() is preferred`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d2d6aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) tensor([[1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "matrix = torch.ones((2, 3), dtype=torch.float)\n",
    "\n",
    "# Reshaping the tensor to shape of (1, 6)\n",
    "reshape_matrix_1 = matrix.view(1, 6)\n",
    "\n",
    "print(matrix, reshape_matrix_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb118a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 4., 1.],\n",
      "        [1., 1., 1.]]) tensor([[1., 4., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# If we change one entry of reshape_matrix_1, then that change will get reflected\n",
    "# in matrix\n",
    "reshape_matrix_1[0, 1] = 4\n",
    "print(matrix, reshape_matrix_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6ec832",
   "metadata": {},
   "source": [
    "`To create new, independent tensor with different shape, we can use new_tensor() or clone() methods`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6a964da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 3., 1., 1., 1., 1.]])\n",
      "tensor([[1., 4., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/09/3m09y2cx0cq_1x4gp8q0ng2m0000gn/T/ipykernel_85400/1829998365.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  new_matrix = matrix.new_tensor(matrix.view(1, 6))\n"
     ]
    }
   ],
   "source": [
    "# Creating new and independent matrix using new_tensor() method\n",
    "new_matrix = matrix.new_tensor(matrix.view(1, 6))\n",
    "\n",
    "# Chaging the element of new matrix\n",
    "new_matrix[0, 1] = 3\n",
    "\n",
    "print(new_matrix)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79e396a",
   "metadata": {},
   "source": [
    "`Above we can see that pytorch throws warning while using new_tensor(), So clone() method is prefered over new_tensor()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a988319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 9., 1., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "matrix = torch.ones((2, 3), dtype=torch.float)\n",
    "\n",
    "# Creating duplicate and independent matrix using clone and view method\n",
    "another_matrix = matrix.view(1, 6).clone().detach()\n",
    "\n",
    "# Changing one of the value of another_matrix\n",
    "another_matrix[0, 1] = 9\n",
    "\n",
    "print(another_matrix)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5af8e33",
   "metadata": {},
   "source": [
    "- `We can observe that change in another_matrix is not reflected to matrix`\n",
    "- `detach() method is used to remove the tensor from computation graph`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d138af",
   "metadata": {},
   "source": [
    "## Loading Data, Devices, and CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d800ada",
   "metadata": {},
   "source": [
    "- `as_tensor() method is used to convert the numpy object to pytorch tensors`\n",
    "- `as_tensor() preserves the type of the array`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3569591",
   "metadata": {},
   "source": [
    "### Numpy to PyTorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17822ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64 torch.float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = np.random.rand(2, 3)\n",
    "\n",
    "x_train_tensor = torch.as_tensor(x_train)\n",
    "print(x_train.dtype, x_train_tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1275e2d2",
   "metadata": {},
   "source": [
    "`To cast down the tensor from float64 to float32, we can use float() method to tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84678ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64 torch.float32\n"
     ]
    }
   ],
   "source": [
    "float_tensor = x_train_tensor.float()\n",
    "print(x_train_tensor.dtype, float_tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c94ddd",
   "metadata": {},
   "source": [
    "`Important: Both as_tensor() and from_numpy() return a tensor that shares the underlying data with the original Numpy array. Similar to what happened when we used view() method. I we modify original Numpy array, corresponding PyTorch tensor too gets modified and vice-versa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d65bca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 4.]]\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 4.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "np_array = np.ones(shape=(2, 3))\n",
    "\n",
    "pt_tensor = torch.as_tensor(np_array)\n",
    "\n",
    "# changing the value of pt_tensor\n",
    "pt_tensor[1, 2] = 4\n",
    "print(np_array)\n",
    "print(pt_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198a0e26",
   "metadata": {},
   "source": [
    "`Difference between as_tensor() and torch.tensor(): torch.tensor() always makes a copy of the data instead of sharing the underlu=ying data woth the Numpy array`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8464167b",
   "metadata": {},
   "source": [
    "### PyTorch Tensor to Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0a7942",
   "metadata": {},
   "source": [
    "`We can convert PyTorch tensor back to numpy array using numpy() method`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39f051ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.11799011 0.28302073 0.63657481]\n",
      " [0.92466622 0.24974654 0.53397068]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "array = np.random.rand(2, 3)\n",
    "\n",
    "pt_tensor = torch.as_tensor(array)\n",
    "\n",
    "print(pt_tensor.numpy(), type(pt_tensor.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafe726c",
   "metadata": {},
   "source": [
    "### GPU Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb54356",
   "metadata": {},
   "source": [
    "`Check if CUDA is available`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b8cabe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b492037",
   "metadata": {},
   "source": [
    "`Checking cuda count and it's names`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43ac71a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cudas = torch.cuda.device_count()\n",
    "for i in range(n_cudas):\n",
    "    print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816aba41",
   "metadata": {},
   "source": [
    "`Turning tensor into GPU tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49d7170a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6479, 0.1499, 0.5774], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# converting the training numpy array to a tensor first and then to a GPU tensor\n",
    "gpu_tensor = torch.as_tensor(x_train).to(device)\n",
    "print(gpu_tensor[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d4fc55",
   "metadata": {},
   "source": [
    "`Converting GPU tensor to Numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fcee3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# PyTorch tensor\n",
    "pt_tensor = torch.ones(size=(2, 3)).to(device)\n",
    "\n",
    "numpy_array = pt_tensor.cpu().numpy()\n",
    "print(numpy_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be48414",
   "metadata": {},
   "source": [
    "`Unfortunately, Numpy cannot handle GPU tensors. You need to make them CPU tensors first using cpu() method. So to avoid this error, first use cpu() and then numpy() even if you are using CPU.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c28eee7",
   "metadata": {},
   "source": [
    "## Creating Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641e7f2f",
   "metadata": {},
   "source": [
    "`Parameters can be created in three ways`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07887314",
   "metadata": {},
   "source": [
    "### First Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5b568d",
   "metadata": {},
   "source": [
    "- `Creating tensor with parameter requires_grad=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40f1a8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "w = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a536b0",
   "metadata": {},
   "source": [
    "`This method will create parameter only for CPU, It will not work for GPU`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ab026b",
   "metadata": {},
   "source": [
    "### Second Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfd4ba9",
   "metadata": {},
   "source": [
    "`Creating Parameters with requires_grad=True and sending it to GPU using .to(device) method`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0bc450a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ccde5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
    "w = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190ef376",
   "metadata": {},
   "source": [
    "`In case of GPU, the outcome will be:`\n",
    "- `tensor([0.3367], decive=\"cuda:0\", grad_fn=<CopyBackward>)`\n",
    "- `tensor([0.1288], device=\"cuda:0\", grad_fn=<CopyBackward>)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f657b415",
   "metadata": {},
   "source": [
    "`With this approach, gradient of parameter is lost while transferring the parameter from CPU to GPU`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c87fc21",
   "metadata": {},
   "source": [
    "### Third Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cec8d0",
   "metadata": {},
   "source": [
    "`In this approach we send our tensors to the device and then use the requires_grad_() method to set its requires_grad() attribute to True`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb8fdf9",
   "metadata": {},
   "source": [
    "**In PyTorch, every method that ends with an underscore ( _ ) like the requires_grad_() method above, makes changes in-place; meaning, they will modify the underlying variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "29f434b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, dtype=torch.float).to(device)\n",
    "w = torch.randn(1, dtype=torch.float).to(device)\n",
    "\n",
    "b.requires_grad_()\n",
    "w.requires_grad_()\n",
    "\n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82180475",
   "metadata": {},
   "source": [
    "`In case of GPU, the output will be:`\n",
    "- `tensor([0.3367], device=\"cuda:0\", requires_grad=True)`\n",
    "- `tensor([0.1288], device=\"cuda:0\", requires_grad=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b64d6b4",
   "metadata": {},
   "source": [
    "`This approach works fine but there is a better way to handle this and remove the effort of using requires_grad_() for each trainable parameter`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dd731c",
   "metadata": {},
   "source": [
    "### Fourth Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "213edf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "\n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73f32cd",
   "metadata": {},
   "source": [
    "`In case of GPU, the output will be:`\n",
    "- `tensor([0.1940], device=\"cuda:0\", requires_grad=True)`\n",
    "- `tensor([0.1391], device=\"cuda:0\", requires_grad=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d324f2",
   "metadata": {},
   "source": [
    "`Although torch.manual_seeds are same but for GPU, tensor values will be different because for GPU random generator generates different sequence compared to CPU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff19eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
